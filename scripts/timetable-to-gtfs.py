#!/usr/bin/env python3
# -*- coding: utf-8 -*-

# Generated by ChatGPT-5
# https://chatgpt.com/share/690d735d-3fb4-8013-9847-8d558b7feb8a

"""
Multi-sheet converter: wide timetable spreadsheet(s) -> GTFS trips.txt and stop_times.txt

Features:
- Reads route_id from the cell to the right of "Route".
- Reads default direction from "Direction" or "Direction ID" (cell to the right),
  mapping words and numbers:
    Outbound/Onward/0 -> 0
    Inbound/Reverse/1 -> 1
- Also accepts a per-row "Direction" or "Direction ID" metadata column (overrides the default).
- Honors a per-row "Trip ID" column (to the left of Calendar service and Headsign).
  If blank, generates trip_id including *line + direction* (e.g., blue_outbound_00001).
- Detects metadata headers (Trip ID, Calendar service, Headsign, Direction) in the
  FIRST ROW BELOW the Arrive/Depart row.
- Works across multiple sheets, merging outputs.

Usage:
    python timetable_to_gtfs_multi.py "Lagos data.xlsx" \
      --sheets "BLUE-Inbound,BLUE-Outbound,RED-Inbound,RED-Outbound" \
      --outdir ./gtfs_out

Notes:
- Stop-name header row is immediately ABOVE the Arrive/Depart row.
- Times may be HH:MM or HH:MM:SS or Excel day-fractions (0–3).
"""

import argparse, os, re, sys
from typing import Optional, List, Tuple, Dict
import pandas as pd

ARRIVE_LABELS = {"arrive","arrival","arr","arr."}
DEPART_LABELS = {"depart","departure","dep","dep."}

DIR_MAP = {
    "outbound": 0, "onward": 0, "0": 0, 0: 0,
    "inbound": 1, "reverse": 1, "1": 1, 1: 1
}

def slugify(value: str) -> str:
    value = str(value or "").strip()
    value = re.sub(r"\([^)]*\)", "", value)
    value = re.sub(r"[^A-Za-z0-9]+", "_", value).strip("_")
    return value.lower() or "x"

def parse_time_cell(x) -> Optional[str]:
    if pd.isna(x): return None
    if isinstance(x, (pd.Timestamp, )):
        return f"{x.hour:02d}:{x.minute:02d}:{x.second:02d}"
    if isinstance(x, (int, float)):
        # Excel day-fraction (0–3 days)
        if 0 <= float(x) <= 3:
            secs = int(round(float(x) * 86400))
            h, rem = divmod(secs, 3600); m, s = divmod(rem, 60)
            return f"{h:02d}:{m:02d}:{s:02d}"
    s = str(x).strip()
    m = re.match(r"^\s*(\d{1,3}):(\d{1,2})(?::(\d{1,2}))?\s*$", s)
    if m:
        h=int(m.group(1)); mi=int(m.group(2)); se=int(m.group(3)) if m.group(3) else 0
        return f"{h:02d}:{mi:02d}:{se:02d}"
    try:
        ts = pd.to_datetime(s, errors="raise")
        return f"{ts.hour:02d}:{ts.minute:02d}:{ts.second:02d}"
    except Exception:
        return None

def find_value_to_right(df: pd.DataFrame, label: str, search_rows: int = 6) -> Optional[str]:
    lbl = label.strip().lower()
    for r in range(min(search_rows, len(df))):
        for c in range(df.shape[1]-1):
            if str(df.iat[r,c]).strip().lower() == lbl:
                v = df.iat[r,c+1]
                return None if pd.isna(v) else str(v).strip()
    return None

def coerce_dir(val: Optional[str], fallback: Optional[int]=None) -> Optional[int]:
    if val is None:
        return fallback
    s=str(val).strip().lower()
    return DIR_MAP.get(s, fallback)

def detect_stop_headers(df: pd.DataFrame):
    sub_idx=None
    for i in range(min(12, len(df))):
        labels=set(str(x).strip().lower() for x in df.iloc[i].tolist())
        if (labels & ARRIVE_LABELS) or (labels & DEPART_LABELS):
            sub_idx=i; break
    if sub_idx is None: raise ValueError("Arrive/Depart subheader row not found.")
    stop_idx = sub_idx-1
    stop_cols=[]
    for c in range(df.shape[1]):
        kind=str(df.iat[sub_idx,c]).strip().lower()
        if kind in ARRIVE_LABELS or kind in DEPART_LABELS:
            stop_cols.append((c, str(df.iat[stop_idx,c]).strip(), "arrive" if kind in ARRIVE_LABELS else "depart"))
    first_time_col=min(c for c,_,_ in stop_cols)
    return stop_idx, sub_idx, stop_cols, first_time_col

def find_meta_row(df: pd.DataFrame, sub_idx: int, first_time_col: int) -> Optional[int]:
    targets={
        'trip id','trip_id','calendar service','service','service id','service_id',
        'headsign','trip headsign','trip_headsign','direction id','direction','direction_id'
    }
    for r in range(sub_idx+1, min(sub_idx+6, len(df))):
        vals=[str(v).strip().lower() for v in df.iloc[r,:first_time_col].tolist()]
        if any(v in targets for v in vals):
            return r
    return None

def build_from_sheet(df: pd.DataFrame, sheet_name: str):
    route_id = find_value_to_right(df, "Route") or "ROUTE"
    default_dir = coerce_dir(find_value_to_right(df, "Direction"))
    if default_dir is None:
        default_dir = coerce_dir(find_value_to_right(df, "Direction ID"))
    if default_dir is None:  # infer from sheet name
        if any(k in sheet_name.lower() for k in ["outbound","onward","0"]): default_dir=0
        elif any(k in sheet_name.lower() for k in ["inbound","reverse","1"]): default_dir=1

    stop_idx, sub_idx, stop_cols, first_time_col = detect_stop_headers(df)
    meta_row = find_meta_row(df, sub_idx, first_time_col)

    # Map metadata columns (Trip ID is to the LEFT of Calendar/Headsign in your layout)
    tripid_col = svc_col = head_col = dir_col = None
    if meta_row is not None:
        labels=[str(v).strip().lower() for v in df.iloc[meta_row, :first_time_col].tolist()]
        def idx_for(*names):
            names=[n.replace(" ","") for n in names]
            for i,lbl in enumerate(labels):
                if lbl.replace(" ","") in names: return i
            return None
        tripid_col = idx_for("trip id","trip_id")
        svc_col    = idx_for("calendar service","service","serviceid","service_id")
        head_col   = idx_for("headsign","trip headsign","trip_headsign")
        dir_col    = idx_for("direction id","direction","direction_id","directionid")

    # Build stop list and IDs
    stop_order=[]; seen=set()
    for c,name,kind in stop_cols:
        if name not in seen: seen.add(name); stop_order.append(name)

    line_slug = slugify(route_id)
    trips=[]; stop_times=[]; counter=1; used_ids=set()

    data_start = (meta_row+1) if meta_row is not None else (sub_idx+1)
    for r in range(data_start, df.shape[0]):
        row = df.iloc[r]
        # Collect times
        times={s: {"arrive":None, "depart":None} for s in stop_order}
        for c,name,kind in stop_cols:
            t=parse_time_cell(row.iloc[c])
            if t: times[name][kind]=t
        non_null=sum(1 for s in stop_order for k in ("arrive","depart") if times[s][k])
        if non_null < 2:
            continue

        # Row metadata
        manual_trip_id=None
        if tripid_col is not None and pd.notna(row.iloc[tripid_col]):
            txt=str(row.iloc[tripid_col]).strip()
            manual_trip_id = txt if txt != "" else None

        service_id="WEEKDAY"
        if svc_col is not None and pd.notna(row.iloc[svc_col]):
            v=str(row.iloc[svc_col]).strip()
            if v: service_id=v

        headsign=None
        if head_col is not None and pd.notna(row.iloc[head_col]):
            v=str(row.iloc[head_col]).strip()
            if v: headsign=v

        direction_id=default_dir
        if dir_col is not None and pd.notna(row.iloc[dir_col]):
            direction_id = coerce_dir(str(row.iloc[dir_col]).strip(), fallback=direction_id)

        # Trip ID: use manual if present; else generate with line+direction
        if manual_trip_id:
            trip_id = manual_trip_id
        else:
            dir_token = "outbound" if direction_id == 0 else "inbound" if direction_id == 1 else "dirx"
            trip_id = f"{line_slug}_{dir_token}_{counter:05d}"
        # ensure uniqueness across sheets
        base = trip_id; suffix = 1
        while trip_id in used_ids:
            trip_id = f"{base}_{suffix}"; suffix += 1
        used_ids.add(trip_id)
        counter += 1

        trip = {"route_id": route_id, "service_id": service_id, "trip_id": trip_id}
        if direction_id is not None: trip["direction_id"] = direction_id
        if headsign: trip["trip_headsign"] = headsign
        trips.append(trip)

        seq = 1
        for s in stop_order:
            arr = times[s]["arrive"]; dep = times[s]["depart"]
            if not arr and dep: arr = dep
            if not dep and arr: dep = arr
            if not arr and not dep: continue
            stop_times.append({
                "trip_id": trip_id,
                "arrival_time": arr,
                "departure_time": dep,
                "stop_id": s,
                "stop_sequence": seq
            })
            seq += 1

        if seq <= 2:
            trips.pop()
            stop_times = [st for st in stop_times if st["trip_id"] != trip_id]

    trips_df = pd.DataFrame(trips)
    stop_times_df = pd.DataFrame(stop_times).sort_values(["trip_id","stop_sequence"]).reset_index(drop=True)
    return trips_df, stop_times_df

def main():
    ap = argparse.ArgumentParser()
    ap.add_argument("input", help=".xlsx/.xls/.csv workbook")
    ap.add_argument("--sheets", help="Comma-separated list of sheets to process")
    ap.add_argument("--outdir", default=".", help="Output directory")
    args = ap.parse_args()

    # Load workbook
    if args.input.lower().endswith((".xlsx",".xls")):
        xls = pd.ExcelFile(args.input)
        requested = [s.strip() for s in (args.sheets.split(",") if args.sheets else xls.sheet_names)]
        found = [s for s in requested if s in xls.sheet_names]
        if not found:
            print("None of the requested sheets exist in the workbook.", file=sys.stderr)
            sys.exit(1)
        all_trips=[]; all_st=[]
        for s in found:
            df = pd.read_excel(args.input, sheet_name=s, header=None)
            t, st = build_from_sheet(df, s)
            all_trips.append(t); all_st.append(st)
        trips_df = pd.concat(all_trips, ignore_index=True)
        stop_times_df = pd.concat(all_st, ignore_index=True)
    elif args.input.lower().endswith(".csv"):
        df = pd.read_csv(args.input, header=None)
        trips_df, stop_times_df = build_from_sheet(df, "sheet")
    else:
        print("Unsupported input; use .xlsx/.xls/.csv", file=sys.stderr); sys.exit(1)

    os.makedirs(args.outdir, exist_ok=True)
    trips_cols = ["route_id","service_id","trip_id"]
    if "direction_id" in trips_df.columns: trips_cols.append("direction_id")
    if "trip_headsign" in trips_df.columns: trips_cols.append("trip_headsign")
    trips_df[trips_cols].to_csv(os.path.join(args.outdir, "trips.txt"), index=False)
    stop_times_df[["trip_id","arrival_time","departure_time","stop_id","stop_sequence"]].to_csv(
        os.path.join(args.outdir, "stop_times.txt"), index=False
    )

if __name__ == "__main__":
    main()
